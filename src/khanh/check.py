from google import genai
from google.genai import types
import itertools
import time
import json
import random
import re

# ==========================================
API_KEYS = [

]

# ==========================================
MODELS = [
    "gemini-2.0-flash",       
    "gemini-2.5-flash",  
    "gemini-robotics-er-1.5-preview",
    "gemini-2.5-flash-lite",
    "gemini-2.0-flash-lite",
    "learnlm-2.0-flash-experimental",
]

# ==========================================
api_cycle = itertools.cycle(API_KEYS)
model_cycle = itertools.cycle(MODELS)


def create_client():
    """T·∫°o client m·ªõi v·ªõi API key k·∫ø ti·∫øp"""
    api_key = next(api_cycle)
    return genai.Client(api_key=api_key)


# ==========================================
def safe_load_json(raw: str):
    """L√†m s·∫°ch chu·ªói model tr·∫£ v·ªÅ v√† parse JSON an to√†n"""
    if not raw or not isinstance(raw, str):
        return None

    # Lo·∫°i b·ªè markdown ho·∫∑c k√Ω t·ª± ```json
    cleaned = re.sub(r"^```(?:json)?|```$", "", raw.strip(), flags=re.MULTILINE)

    # T√¨m ƒëo·∫°n JSON ƒë·∫ßu ti√™n trong text
    match = re.search(r"\{[\s\S]*\}", cleaned)
    if not match:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y JSON trong output.")
        return None

    json_str = match.group(0)

    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        print(f"‚ö†Ô∏è JSONDecodeError: {e}")
        print("----- RAW (preview) -----")
        print(raw[:400])
        print("--------------------------")
        return None


# ==========================================
def check_sentences(sentences):
    client = create_client()
    model = next(model_cycle)

    prompt = f"""
            Nhi·ªám v·ª•: Ki·ªÉm tra xem t·ª´ng c√¢u trong danh s√°ch sau c√≥ t·ªìn t·∫°i nguy√™n vƒÉn tr√™n Google hay kh√¥ng.

            Y√™u c·∫ßu:
            1. T√¨m ki·∫øm ch√≠nh x√°c tr√™n Google v√† tr·∫£ v·ªÅ t·ªëi ƒëa 5 url.
            2. Tr·∫£ JSON duy nh·∫•t, kh√¥ng k√®m vƒÉn b·∫£n hay markdown.
            3. C·∫•u tr√∫c JSON:
            {{
            "results": [
                {{
                "query": "<c√¢u 1>",
                "exists": true ho·∫∑c false,
                "links": ["https://...", ...]
                }},
                ...
            ]
            }}

            Danh s√°ch c√¢u c·∫ßn ki·ªÉm tra:
            {chr(10).join([f'{i+1}. "{s}"' for i, s in enumerate(sentences)])}
        """

    config = types.GenerateContentConfig(
        tools=[
            types.Tool(
                google_search=types.GoogleSearch()
            )
        ]
    )

    try:
        response = client.models.generate_content(
            model=model,
            contents=prompt,
            config=config
        )
        return response.text.strip()

    except Exception as e:
        print(f"[‚ö†Ô∏è L·ªói] {type(e).__name__}: {e}")
        # N·∫øu l·ªói quota ho·∫∑c rate limit, th·ª≠ l·∫°i v·ªõi model kh√°c v√† key kh√°c
        time.sleep(random.uniform(2, 5))
        return check_sentences(sentences)


# ==========================================
def batch_check(all_sentences, batch_size=10):
    results = []

    for i in range(0, len(all_sentences), batch_size):
        batch = all_sentences[i:i + batch_size]
        print(f"\nüîç Ki·ªÉm tra batch {i//batch_size + 1} ({len(batch)} c√¢u)...")

        raw = check_sentences(batch)
        print(f"üìÑ Raw response:\n{raw}\n")

        data = safe_load_json(raw)
        if data and "results" in data:
            results.extend(data["results"])
        else:
            print("‚ö†Ô∏è JSON l·ªói ho·∫∑c kh√¥ng h·ª£p l·ªá, b·ªè qua batch n√†y.")

        time.sleep(random.uniform(3, 6))  # tr√°nh gi·ªõi h·∫°n RPM
    with open("check.json", "w", encoding="utf-8") as f:
        json.dump({"results": results}, f, ensure_ascii=False, indent=2)
    return {"results": results}


# ==========================================
if __name__ == "__main__":
    sentences = [
        "Ngay t·ª´ nh·ªè, ch√∫ng ta ƒë√£ c√≥ kh√°i ni·ªám v·ªÅ ti·ªÅn b·∫°c.",
        "ƒê√≥ l√† m·ªôt cu·ªôc chi·∫øn m√† ƒë·ªìng ti·ªÅn l√† s√∫ng ƒë·∫°n v√† m·ª©c s√°t th∆∞∆°ng th·∫≠t l√† gh√™ g·ªõm.",
        "Cu·ªôc s·ªëng l√† chu·ªói ng√†y h·ªçc h·ªèi v√† tr·∫£i nghi·ªám, v√¨ v·∫≠y h√£y bi·∫øt ∆°n n√≥.",
        "H·∫°nh ph√∫c kh√¥ng ph·∫£i l√† ƒë√≠ch ƒë·∫øn m√† l√† h√†nh tr√¨nh ta tr·∫£i qua m·ªói ng√†y.",
        "Th√†nh c√¥ng kh√¥ng ƒëo b·∫±ng ti·ªÅn b·∫°c m√† b·∫±ng s·ª± h√†i l√≤ng trong t√¢m h·ªìn.",
        "N·∫øu tui l√† gia c√°t l∆∞·ª£ng th√¨ tui ƒë√£ kh√¥ng ƒë·ªÉ cho ng∆∞∆°i l√†m vi·ªác n√†y.",
    ]

    final_result = batch_check(sentences, batch_size=2)
    print("\n‚úÖ K·∫øt qu·∫£ cu·ªëi c√πng:")
    print(json.dumps(final_result, ensure_ascii=False, indent=2))
